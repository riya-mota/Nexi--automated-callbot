{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# F5-TTS Voice Cloning - Simplified Error-Free Approach\n",
        "# Run each cell step by step in Google Colab\n",
        "\n",
        "# ================================\n",
        "# CELL 1: Environment Setup\n",
        "# ================================\n",
        "print(\"üöÄ Starting F5-TTS Voice Cloning Setup...\")\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install essential packages\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def run_command(cmd):\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Error: {result.stderr}\")\n",
        "    return result.returncode == 0\n",
        "\n",
        "# Install dependencies\n",
        "print(\"Installing core packages...\")\n",
        "\n",
        "# Use the official PyTorch installation command for CUDA 11.8\n",
        "# This ensures torch, torchaudio, and torchdata are compatible\n",
        "run_command(\"pip install torch==2.1.0 torchaudio==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118\")\n",
        "\n",
        "# Install other dependencies\n",
        "run_command(\"pip install transformers>=4.35.0\")\n",
        "run_command(\"pip install librosa soundfile pydub numpy scipy\")\n",
        "run_command(\"pip install accelerate safetensors\")\n",
        "run_command(\"pip install ffmpeg-python\") # Added ffmpeg-python for pydub compatibility\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7r-pxYyiM4y",
        "outputId": "407f218b-3e3a-4e70-eabd-81e7f71d1d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting F5-TTS Voice Cloning Setup...\n",
            "Mounted at /content/drive\n",
            "Installing core packages...\n",
            "‚úÖ Environment setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/drive/MyDrive/voice cloning/reference_audio.wav\""
      ],
      "metadata": {
        "id": "p4oiQUGZiSaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüì¶ Setting up F5-TTS...\")\n",
        "\n",
        "os.chdir('/content')\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists('F5-TTS'):\n",
        "    run_command('rm -rf F5-TTS')\n",
        "\n",
        "# Clone repository\n",
        "print(\"Cloning F5-TTS repository...\")\n",
        "if run_command('git clone https://github.com/SWivid/F5-TTS.git'):\n",
        "    print(\"‚úÖ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to clone repository\")\n",
        "\n",
        "# Install F5-TTS\n",
        "os.chdir('/content/F5-TTS')\n",
        "run_command('pip install -e .')\n",
        "run_command('pip install -r requirements.txt')\n",
        "\n",
        "print(\"‚úÖ F5-TTS installation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np_txatbihHK",
        "outputId": "9155c663-fb8b-4ef1-b457-b4b27f364969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¶ Setting up F5-TTS...\n",
            "Cloning F5-TTS repository...\n",
            "‚úÖ Repository cloned successfully!\n",
            "Error: ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
            "\n",
            "‚úÖ F5-TTS installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTja-DCtuqnK",
        "outputId": "31de8b05-5f04-46dd-af2d-47cf5d6d00a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Preparing text data...\n",
            "Reference text: You just tell me what works, date, time, and your preferred location. We'll arrange everything for you. No pressure. Seriously. I'm just here to help you\n",
            "\n",
            "Target text: Hey Welcome to Nexi, I'm your personal assistant to help you with all your jaguar land rover queries. We have a wide range of car from SUV to sports, tell me what should i help you with.\n",
            "‚úÖ Texts prepared!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüìù Preparing text data...\")\n",
        "\n",
        "# Your texts\n",
        "reference_text = \"You just tell me what works, date, time, and your preferred location. We'll arrange everything for you. No pressure. Seriously. I'm just here to help you\"\n",
        "\n",
        "target_text = \"Hey Welcome to Nexi, I'm your personal assistant to help you with all your jaguar land rover queries. We have a wide range of car from SUV to sports, tell me what should i help you with.\"\n",
        "\n",
        "print(\"Reference text:\", reference_text)\n",
        "print(\"\\nTarget text:\", target_text)\n",
        "print(\"‚úÖ Texts prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FastAPI Fix - Run this to kill previous server and start fresh\n",
        "\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "print(\"üîß Fixing port conflict...\")\n",
        "\n",
        "# Method 1: Kill processes on port 5000\n",
        "print(\"1Ô∏è‚É£ Killing processes on port 5000...\")\n",
        "try:\n",
        "    # Find and kill processes using port 5000\n",
        "    result = subprocess.run(['lsof', '-ti:5000'], capture_output=True, text=True)\n",
        "    if result.stdout:\n",
        "        pids = result.stdout.strip().split('\\n')\n",
        "        for pid in pids:\n",
        "            if pid:\n",
        "                try:\n",
        "                    os.kill(int(pid), signal.SIGTERM)\n",
        "                    print(f\"   Killed process {pid}\")\n",
        "                except:\n",
        "                    pass\n",
        "    else:\n",
        "        print(\"   No processes found on port 5000\")\n",
        "except:\n",
        "    print(\"   lsof command not available, trying alternative...\")\n",
        "\n",
        "# Method 2: Alternative kill method\n",
        "try:\n",
        "    subprocess.run(['pkill', '-f', 'uvicorn'], capture_output=True)\n",
        "    subprocess.run(['pkill', '-f', 'flask'], capture_output=True)\n",
        "    print(\"   Killed uvicorn and flask processes\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Wait a moment\n",
        "time.sleep(2)\n",
        "\n",
        "# Method 3: Use a different port\n",
        "print(\"2Ô∏è‚É£ Starting FastAPI on port 8000 instead...\")\n",
        "\n",
        "# Install FastAPI and dependencies\n",
        "!pip install fastapi uvicorn python-multipart -q\n",
        "\n",
        "from fastapi import FastAPI, HTTPException, BackgroundTasks\n",
        "from fastapi.responses import FileResponse, JSONResponse\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "from typing import Optional\n",
        "\n",
        "# Global variable to store the target text from API\n",
        "api_target_text = None\n",
        "api_ready = False\n",
        "\n",
        "# Pydantic models for request/response\n",
        "class VoiceRequest(BaseModel):\n",
        "    target_text: str\n",
        "\n",
        "class VoiceResponse(BaseModel):\n",
        "    status: str\n",
        "    message: str\n",
        "    target_text: str\n",
        "\n",
        "class HealthResponse(BaseModel):\n",
        "    status: str\n",
        "    message: str\n",
        "    timestamp: float\n",
        "    service: str\n",
        "\n",
        "class StatusResponse(BaseModel):\n",
        "    api_ready: bool\n",
        "    target_text_received: bool\n",
        "    audio_generated: bool\n",
        "    current_target_text: Optional[str]\n",
        "\n",
        "# Create FastAPI app\n",
        "app = FastAPI(\n",
        "    title=\"F5-TTS Voice Cloning API\",\n",
        "    description=\"API for voice cloning using F5-TTS\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "@app.get(\"/health\", response_model=HealthResponse)\n",
        "async def health_check():\n",
        "    \"\"\"Simple health check endpoint to test if API is running\"\"\"\n",
        "    return HealthResponse(\n",
        "        status=\"healthy\",\n",
        "        message=\"Voice Cloning API is running successfully!\",\n",
        "        timestamp=time.time(),\n",
        "        service=\"F5-TTS Voice Cloning API\"\n",
        "    )\n",
        "\n",
        "@app.post(\"/generate_voice\", response_model=VoiceResponse)\n",
        "async def generate_voice_api(request: VoiceRequest):\n",
        "    \"\"\"Receive target text for voice generation\"\"\"\n",
        "    global api_target_text, api_ready\n",
        "\n",
        "    try:\n",
        "        api_target_text = request.target_text\n",
        "        api_ready = True\n",
        "\n",
        "        print(f\"‚úÖ Received target text via API: {api_target_text}\")\n",
        "\n",
        "        return VoiceResponse(\n",
        "            status=\"success\",\n",
        "            message=\"Target text received. Voice generation will start.\",\n",
        "            target_text=api_target_text\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/get_audio\")\n",
        "async def get_generated_audio():\n",
        "    \"\"\"Endpoint to download the generated audio file\"\"\"\n",
        "    try:\n",
        "        audio_files = [\n",
        "            \"/content/generated_voice_fixed.wav\",\n",
        "            \"/content/generated_voice.wav\"\n",
        "        ]\n",
        "\n",
        "        for audio_file in audio_files:\n",
        "            if os.path.exists(audio_file):\n",
        "                return FileResponse(\n",
        "                    audio_file,\n",
        "                    media_type=\"audio/wav\",\n",
        "                    filename=\"generated_voice.wav\"\n",
        "                )\n",
        "\n",
        "        raise HTTPException(status_code=404, detail=\"No generated audio file found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/status\", response_model=StatusResponse)\n",
        "async def get_status():\n",
        "    \"\"\"Check if API is ready and if audio is generated\"\"\"\n",
        "    global api_ready, api_target_text\n",
        "\n",
        "    audio_exists = any(os.path.exists(f) for f in [\n",
        "        \"/content/generated_voice_fixed.wav\",\n",
        "        \"/content/generated_voice.wav\"\n",
        "    ])\n",
        "\n",
        "    return StatusResponse(\n",
        "        api_ready=api_ready,\n",
        "        target_text_received=api_target_text is not None,\n",
        "        audio_generated=audio_exists,\n",
        "        current_target_text=api_target_text\n",
        "    )\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"Root endpoint with API information\"\"\"\n",
        "    return {\n",
        "        \"message\": \"F5-TTS Voice Cloning API\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"endpoints\": {\n",
        "            \"health\": \"/health\",\n",
        "            \"generate_voice\": \"/generate_voice\",\n",
        "            \"get_audio\": \"/get_audio\",\n",
        "            \"status\": \"/status\",\n",
        "            \"docs\": \"/docs\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Stop any existing FastAPI threads\n",
        "print(\"3Ô∏è‚É£ Cleaning up existing threads...\")\n",
        "\n",
        "# Function to run FastAPI app in background on port 8000\n",
        "def run_fastapi_app():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"warning\")\n",
        "\n",
        "# Start FastAPI app in a separate thread\n",
        "print(\"4Ô∏è‚É£ Starting FastAPI on port 8000...\")\n",
        "fastapi_thread = threading.Thread(target=run_fastapi_app, daemon=True)\n",
        "fastapi_thread.start()\n",
        "\n",
        "# Wait for FastAPI to start\n",
        "time.sleep(4)\n",
        "\n",
        "print(\"üöÄ FastAPI Server Started Successfully!\")\n",
        "print(\"üì° NEW API URLs (Port 8000):\")\n",
        "print(\"  GET  http://localhost:8000/health - Health check\")\n",
        "print(\"  POST http://localhost:8000/generate_voice - Send target text\")\n",
        "print(\"  GET  http://localhost:8000/get_audio - Download audio\")\n",
        "print(\"  GET  http://localhost:8000/status - Check status\")\n",
        "print(\"  GET  http://localhost:8000/docs - Interactive docs\")\n",
        "\n",
        "print(\"\\nüß™ JSON Example for POST /generate_voice:\")\n",
        "print('''{\n",
        "  \"target_text\": \"Your text message here\"\n",
        "}''')\n",
        "\n",
        "# Internal health check on new port\n",
        "print(\"\\nüîß Running health check on port 8000...\")\n",
        "try:\n",
        "    import requests\n",
        "    time.sleep(2)\n",
        "    response = requests.get(\"http://localhost:8000/health\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ FastAPI health check passed on port 8000!\")\n",
        "        print(f\"   Response: {response.json()}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Health check failed: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Health check error: {e}\")\n",
        "\n",
        "print(\"\\n‚è≥ Waiting for target text via API...\")\n",
        "print(\"üåê Visit http://localhost:8000/docs for interactive testing!\")\n",
        "print(\"üìç Use PORT 8000 in Postman, not 5000!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QjnR7c9nijG",
        "outputId": "7262603d-1e90-4a8d-e771-6a1ade564f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Fixing port conflict...\n",
            "1Ô∏è‚É£ Killing processes on port 5000...\n",
            "   No processes found on port 5000\n",
            "   Killed uvicorn and flask processes\n",
            "2Ô∏è‚É£ Starting FastAPI on port 8000 instead...\n",
            "3Ô∏è‚É£ Cleaning up existing threads...\n",
            "4Ô∏è‚É£ Starting FastAPI on port 8000...\n",
            "üöÄ FastAPI Server Started Successfully!\n",
            "üì° NEW API URLs (Port 8000):\n",
            "  GET  http://localhost:8000/health - Health check\n",
            "  POST http://localhost:8000/generate_voice - Send target text\n",
            "  GET  http://localhost:8000/get_audio - Download audio\n",
            "  GET  http://localhost:8000/status - Check status\n",
            "  GET  http://localhost:8000/docs - Interactive docs\n",
            "\n",
            "üß™ JSON Example for POST /generate_voice:\n",
            "{\n",
            "  \"target_text\": \"Your text message here\"\n",
            "}\n",
            "\n",
            "üîß Running health check on port 8000...\n",
            "‚úÖ FastAPI health check passed on port 8000!\n",
            "   Response: {'status': 'healthy', 'message': 'Voice Cloning API is running successfully!', 'timestamp': 1750221448.9792147, 'service': 'F5-TTS Voice Cloning API'}\n",
            "\n",
            "‚è≥ Waiting for target text via API...\n",
            "üåê Visit http://localhost:8000/docs for interactive testing!\n",
            "üìç Use PORT 8000 in Postman, not 5000!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FastAPI Test on Port 8000 - Run this in a NEW CELL\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"üß™ Testing FastAPI on Port 8000...\")\n",
        "\n",
        "BASE_URL = \"http://localhost:8000\"\n",
        "\n",
        "# Test 1: Health Check\n",
        "print(\"\\n1Ô∏è‚É£ Health Check Test:\")\n",
        "try:\n",
        "    response = requests.get(f'{BASE_URL}/health', timeout=5)\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ Health check passed!\")\n",
        "    else:\n",
        "        print(\"‚ùå Health check failed!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Health check error: {e}\")\n",
        "    print(\"üîß Make sure your FastAPI is running on port 8000\")\n",
        "    exit()\n",
        "\n",
        "# Test 2: Send Target Text\n",
        "print(\"\\n2Ô∏è‚É£ Sending Target Text:\")\n",
        "test_text = \"Hello from FastAPI on port 8000! This is my test message for voice cloning.\"\n",
        "\n",
        "try:\n",
        "    payload = {\"target_text\": test_text}\n",
        "    response = requests.post(f'{BASE_URL}/generate_voice',\n",
        "                           json=payload,\n",
        "                           timeout=10)\n",
        "\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ Text sent successfully!\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to send text!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Send text error: {e}\")\n",
        "\n",
        "# Test 3: Check Status\n",
        "print(\"\\n3Ô∏è‚É£ Status Check:\")\n",
        "try:\n",
        "    response = requests.get(f'{BASE_URL}/status', timeout=5)\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    status_data = response.json()\n",
        "    print(f\"Status: {json.dumps(status_data, indent=2)}\")\n",
        "\n",
        "    if status_data.get('target_text_received'):\n",
        "        print(\"‚úÖ Target text was received!\")\n",
        "        print(f\"üìù Received text: {status_data.get('current_target_text')}\")\n",
        "    else:\n",
        "        print(\"‚ùå Target text not received!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Status check error: {e}\")\n",
        "\n",
        "print(\"\\nüéØ FastAPI Test Complete!\")\n",
        "print(f\"üí° API Documentation: {BASE_URL}/docs\")\n",
        "print(\"üìç Use PORT 8000 for all your API calls!\")\n",
        "\n",
        "# Show Postman examples\n",
        "print(\"\\nüìÆ Postman Testing Examples:\")\n",
        "print(\"=\"*40)\n",
        "print(\"Health Check:\")\n",
        "print(f\"  GET {BASE_URL}/health\")\n",
        "print(\"\\nSend Text:\")\n",
        "print(f\"  POST {BASE_URL}/generate_voice\")\n",
        "print(\"  Headers: Content-Type: application/json\")\n",
        "print(\"  Body: {\\\"target_text\\\": \\\"Your message here\\\"}\")\n",
        "print(\"\\nCheck Status:\")\n",
        "print(f\"  GET {BASE_URL}/status\")"
      ],
      "metadata": {
        "id": "zeM-AtN8ylx_",
        "outputId": "7b76c209-a487-4a87-e046-35e469ec5128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing FastAPI on Port 8000...\n",
            "\n",
            "1Ô∏è‚É£ Health Check Test:\n",
            "Status Code: 200\n",
            "Response: {\n",
            "  \"status\": \"healthy\",\n",
            "  \"message\": \"Voice Cloning API is running successfully!\",\n",
            "  \"timestamp\": 1750221454.2774675,\n",
            "  \"service\": \"F5-TTS Voice Cloning API\"\n",
            "}\n",
            "‚úÖ Health check passed!\n",
            "\n",
            "2Ô∏è‚É£ Sending Target Text:\n",
            "‚úÖ Received target text via API: Hello from FastAPI on port 8000! This is my test message for voice cloning.\n",
            "Status Code: 200\n",
            "Response: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Target text received. Voice generation will start.\",\n",
            "  \"target_text\": \"Hello from FastAPI on port 8000! This is my test message for voice cloning.\"\n",
            "}\n",
            "‚úÖ Text sent successfully!\n",
            "\n",
            "3Ô∏è‚É£ Status Check:\n",
            "Status Code: 200\n",
            "Status: {\n",
            "  \"api_ready\": true,\n",
            "  \"target_text_received\": true,\n",
            "  \"audio_generated\": false,\n",
            "  \"current_target_text\": \"Hello from FastAPI on port 8000! This is my test message for voice cloning.\"\n",
            "}\n",
            "‚úÖ Target text was received!\n",
            "üìù Received text: Hello from FastAPI on port 8000! This is my test message for voice cloning.\n",
            "\n",
            "üéØ FastAPI Test Complete!\n",
            "üí° API Documentation: http://localhost:8000/docs\n",
            "üìç Use PORT 8000 for all your API calls!\n",
            "\n",
            "üìÆ Postman Testing Examples:\n",
            "========================================\n",
            "Health Check:\n",
            "  GET http://localhost:8000/health\n",
            "\n",
            "Send Text:\n",
            "  POST http://localhost:8000/generate_voice\n",
            "  Headers: Content-Type: application/json\n",
            "  Body: {\"target_text\": \"Your message here\"}\n",
            "\n",
            "Check Status:\n",
            "  GET http://localhost:8000/status\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Test Script - Run this in a separate cell to test your API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Test configuration\n",
        "API_BASE_URL = \"http://localhost:5000\"  # Change this if running on different host/port\n",
        "TEST_TEXT = \"Hello, this is a test message from my chatbot API. Can you hear me clearly?\"\n",
        "\n",
        "print(\"üß™ Starting API Test...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test 1: Check if API server is running\n",
        "print(\"\\n1Ô∏è‚É£ Testing API Status...\")\n",
        "try:\n",
        "    response = requests.get(f\"{API_BASE_URL}/status\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        status_data = response.json()\n",
        "        print(\"‚úÖ API Server is running!\")\n",
        "        print(f\"   Status: {json.dumps(status_data, indent=2)}\")\n",
        "    else:\n",
        "        print(f\"‚ùå API Status check failed: {response.status_code}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå Cannot connect to API server: {e}\")\n",
        "    print(\"   Make sure the Flask app is running in the previous cell\")\n",
        "    exit()\n",
        "\n",
        "# Test 2: Send target text via POST\n",
        "print(\"\\n2Ô∏è‚É£ Sending target text via POST...\")\n",
        "try:\n",
        "    payload = {\n",
        "        \"target_text\": TEST_TEXT\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    print(f\"   Sending: {TEST_TEXT}\")\n",
        "\n",
        "    response = requests.post(\n",
        "        f\"{API_BASE_URL}/generate_voice\",\n",
        "        json=payload,\n",
        "        headers=headers,\n",
        "        timeout=10\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(\"‚úÖ POST request successful!\")\n",
        "        print(f\"   Response: {json.dumps(result, indent=2)}\")\n",
        "    else:\n",
        "        print(f\"‚ùå POST request failed: {response.status_code}\")\n",
        "        print(f\"   Error: {response.text}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå POST request failed: {e}\")\n",
        "\n",
        "# Test 3: Check status after sending text\n",
        "print(\"\\n3Ô∏è‚É£ Checking status after sending text...\")\n",
        "try:\n",
        "    time.sleep(1)  # Wait a moment\n",
        "    response = requests.get(f\"{API_BASE_URL}/status\", timeout=5)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        status_data = response.json()\n",
        "        print(\"‚úÖ Status check successful!\")\n",
        "        print(f\"   Updated Status: {json.dumps(status_data, indent=2)}\")\n",
        "\n",
        "        # Verify the text was received\n",
        "        if status_data.get('target_text_received') and status_data.get('current_target_text') == TEST_TEXT:\n",
        "            print(\"‚úÖ Target text was successfully received and stored!\")\n",
        "        else:\n",
        "            print(\"‚ùå Target text was not properly received\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå Status check failed: {response.status_code}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå Status check failed: {e}\")\n",
        "\n",
        "# Test 4: Test error handling (missing target_text)\n",
        "print(\"\\n4Ô∏è‚É£ Testing error handling...\")\n",
        "try:\n",
        "    # Send request without target_text\n",
        "    response = requests.post(\n",
        "        f\"{API_BASE_URL}/generate_voice\",\n",
        "        json={},  # Empty payload\n",
        "        headers={\"Content-Type\": \"application/json\"},\n",
        "        timeout=10\n",
        "    )\n",
        "\n",
        "    if response.status_code == 400:\n",
        "        error_data = response.json()\n",
        "        print(\"‚úÖ Error handling works correctly!\")\n",
        "        print(f\"   Expected 400 error: {error_data}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Unexpected response for empty payload: {response.status_code}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå Error handling test failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üéØ Test Summary:\")\n",
        "print(\"‚úÖ If all tests passed, your API is working correctly!\")\n",
        "print(\"‚úÖ Your voice cloning notebook should now use the text you sent\")\n",
        "print(\"\\nüí° Next steps:\")\n",
        "print(\"1. Check your voice generation cell output\")\n",
        "print(\"2. The target_text variable should now contain your test message\")\n",
        "print(\"3. Voice generation should proceed with your API text\")\n",
        "\n",
        "# Alternative test using curl command (for reference)\n",
        "print(\"\\nüîß Alternative test using curl command:\")\n",
        "print(\"You can also test manually using this curl command:\")\n",
        "print(f\"\"\"\n",
        "curl -X POST {API_BASE_URL}/generate_voice \\\\\n",
        "  -H 'Content-Type: application/json' \\\\\n",
        "  -d '{{\"target_text\": \"Your test message here\"}}'\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nOr check status with:\")\n",
        "print(f\"curl -X GET {API_BASE_URL}/status\")"
      ],
      "metadata": {
        "id": "0d2rrzBJpv_1",
        "outputId": "24f661ad-e872-4873-a14a-897616ca69ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 11:34:56] \"GET /status HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 11:34:56] \"POST /generate_voice HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Starting API Test...\n",
            "==================================================\n",
            "\n",
            "1Ô∏è‚É£ Testing API Status...\n",
            "‚úÖ API Server is running!\n",
            "   Status: {\n",
            "  \"api_ready\": false,\n",
            "  \"audio_generated\": false,\n",
            "  \"current_target_text\": null,\n",
            "  \"target_text_received\": false\n",
            "}\n",
            "\n",
            "2Ô∏è‚É£ Sending target text via POST...\n",
            "   Sending: Hello, this is a test message from my chatbot API. Can you hear me clearly?\n",
            "‚úÖ Received target text via API: Hello, this is a test message from my chatbot API. Can you hear me clearly?\n",
            "‚úÖ POST request successful!\n",
            "   Response: {\n",
            "  \"message\": \"Target text received. Voice generation will start.\",\n",
            "  \"status\": \"success\",\n",
            "  \"target_text\": \"Hello, this is a test message from my chatbot API. Can you hear me clearly?\"\n",
            "}\n",
            "\n",
            "3Ô∏è‚É£ Checking status after sending text...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 11:34:57] \"GET /status HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 11:34:57] \"\u001b[31m\u001b[1mPOST /generate_voice HTTP/1.1\u001b[0m\" 400 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Status check successful!\n",
            "   Updated Status: {\n",
            "  \"api_ready\": true,\n",
            "  \"audio_generated\": false,\n",
            "  \"current_target_text\": \"Hello, this is a test message from my chatbot API. Can you hear me clearly?\",\n",
            "  \"target_text_received\": true\n",
            "}\n",
            "‚úÖ Target text was successfully received and stored!\n",
            "\n",
            "4Ô∏è‚É£ Testing error handling...\n",
            "‚úÖ Error handling works correctly!\n",
            "   Expected 400 error: {'error': 'target_text parameter is required'}\n",
            "\n",
            "==================================================\n",
            "üéØ Test Summary:\n",
            "‚úÖ If all tests passed, your API is working correctly!\n",
            "‚úÖ Your voice cloning notebook should now use the text you sent\n",
            "\n",
            "üí° Next steps:\n",
            "1. Check your voice generation cell output\n",
            "2. The target_text variable should now contain your test message\n",
            "3. Voice generation should proceed with your API text\n",
            "\n",
            "üîß Alternative test using curl command:\n",
            "You can also test manually using this curl command:\n",
            "\n",
            "curl -X POST http://localhost:5000/generate_voice \\\n",
            "  -H 'Content-Type: application/json' \\\n",
            "  -d '{\"target_text\": \"Your test message here\"}'\n",
            "\n",
            "\n",
            "Or check status with:\n",
            "curl -X GET http://localhost:5000/status\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüé§ Generating cloned voice...\")\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "sys.path.append('/content/F5-TTS/src')\n",
        "\n",
        "# Set device first (fix for device not defined error)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Fix the tensor/tuple issue by using direct inference approach\n",
        "try:\n",
        "    # Import necessary modules (remove problematic import)\n",
        "    from f5_tts.model import DiT, UNetT\n",
        "    from f5_tts.infer.utils_infer import (\n",
        "        load_checkpoint,\n",
        "        preprocess_ref_audio_text,\n",
        "        infer_process,\n",
        "        load_vocoder\n",
        "        # Removed remove_silence as it's causing import error\n",
        "    )\n",
        "    import torchaudio.transforms as T\n",
        "\n",
        "    print(\"‚úÖ F5-TTS modules imported successfully!\")\n",
        "\n",
        "    # Load model configuration\n",
        "    model_cfg = dict(\n",
        "        dim=1024,\n",
        "        depth=22,\n",
        "        heads=16,\n",
        "        ff_mult=2,\n",
        "        text_dim=512,\n",
        "        conv_layers=4\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    print(\"Loading F5-TTS model...\")\n",
        "    model = DiT(**model_cfg)\n",
        "\n",
        "    # Load checkpoint with proper device handling\n",
        "    ckpt_path = \"hf://SWivid/F5-TTS/F5TTS_Base/model_1200000.safetensors\"\n",
        "    model, _, _ = load_checkpoint(model, ckpt_path, device=str(device))\n",
        "\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    # Process reference audio and text\n",
        "    print(\"Processing reference audio...\")\n",
        "    ref_audio, ref_text = preprocess_ref_audio_text(\n",
        "        output_path,\n",
        "        reference_text,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"Generating speech... This will take several minutes...\")\n",
        "\n",
        "    # Generate audio using infer_process\n",
        "    final_wave, final_sample_rate, spectrogram = infer_process(\n",
        "        ref_audio=ref_audio,\n",
        "        ref_text=ref_text,\n",
        "        gen_text=target_text,\n",
        "        model=model,\n",
        "        cross_fade_duration=0.15,\n",
        "        speed=1.0,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Fix the tuple/tensor issue by ensuring proper tensor format\n",
        "    if isinstance(final_wave, tuple):\n",
        "        final_wave = final_wave[0]  # Take first element if it's a tuple\n",
        "\n",
        "    # Ensure tensor is in correct format and shape\n",
        "    if len(final_wave.shape) == 1:\n",
        "        final_wave = final_wave.unsqueeze(0)  # Add channel dimension if needed\n",
        "    elif len(final_wave.shape) == 3:\n",
        "        final_wave = final_wave.squeeze(0)  # Remove batch dimension if present\n",
        "\n",
        "    # Make sure we have the right shape: [channels, samples]\n",
        "    if final_wave.shape[0] > final_wave.shape[1]:\n",
        "        final_wave = final_wave.transpose(0, 1)\n",
        "\n",
        "    # Save the generated audio\n",
        "    output_file = \"/content/generated_voice.wav\"\n",
        "    torchaudio.save(output_file, final_wave.cpu(), final_sample_rate)\n",
        "\n",
        "    print(f\"‚úÖ Voice generation complete!\")\n",
        "    print(f\"Generated file: {output_file}\")\n",
        "\n",
        "    # Create a simple silence removal function instead of using the problematic import\n",
        "    def simple_remove_silence(audio, sample_rate, threshold=0.01):\n",
        "        \"\"\"Simple silence removal based on amplitude threshold\"\"\"\n",
        "        audio_np = audio.numpy() if hasattr(audio, 'numpy') else audio\n",
        "        if len(audio_np.shape) > 1:\n",
        "            audio_np = audio_np[0]  # Take first channel\n",
        "\n",
        "        # Find non-silent segments\n",
        "        non_silent = np.abs(audio_np) > threshold\n",
        "        if np.any(non_silent):\n",
        "            start_idx = np.argmax(non_silent)\n",
        "            end_idx = len(audio_np) - np.argmax(non_silent[::-1]) - 1\n",
        "            return torch.tensor(audio_np[start_idx:end_idx+1])\n",
        "        return torch.tensor(audio_np)\n",
        "\n",
        "    # Create a clean version without silence\n",
        "    try:\n",
        "        clean_wave = simple_remove_silence(final_wave.squeeze().cpu(), final_sample_rate)\n",
        "        clean_output = \"/content/generated_voice_clean.wav\"\n",
        "        torchaudio.save(clean_output, clean_wave.unsqueeze(0), final_sample_rate)\n",
        "        print(f\"‚úÖ Clean version saved: {clean_output}\")\n",
        "    except Exception as clean_error:\n",
        "        print(f\"Note: Clean version creation skipped - {clean_error}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Direct inference failed: {e}\")\n",
        "    print(\"Trying gradio interface approach...\")\n",
        "\n",
        "    # Alternative using gradio interface approach (with device fix)\n",
        "    try:\n",
        "        # Set environment variable to fix hash seed issue\n",
        "        os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "        # Try using the gradio app approach\n",
        "        from f5_tts.infer.infer_gradio import infer, load_model\n",
        "\n",
        "        print(\"Loading model via gradio interface...\")\n",
        "        model, vocoder = load_model(\"F5-TTS\", \"F5TTS_Base\", str(device))\n",
        "\n",
        "        print(\"Generating audio via gradio interface...\")\n",
        "        result = infer(\n",
        "            ref_audio_input=output_path,\n",
        "            ref_text_input=reference_text,\n",
        "            gen_text_input=target_text,\n",
        "            model_obj=model,\n",
        "            vocoder_obj=vocoder,\n",
        "            cross_fade_duration=0.15,\n",
        "            speed=1.0\n",
        "        )\n",
        "\n",
        "        if result:\n",
        "            print(\"‚úÖ Voice generated using gradio interface!\")\n",
        "        else:\n",
        "            print(\"‚ùå Gradio interface approach failed\")\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"‚ùå Gradio approach failed: {e2}\")\n",
        "\n",
        "        # Final fallback - simple file-based approach with fixed tensor handling\n",
        "        print(\"Trying simple file-based generation...\")\n",
        "        try:\n",
        "            # Create a simple script file to avoid CLI issues\n",
        "            script_content = f'''\n",
        "import torch\n",
        "import torchaudio\n",
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('/content/F5-TTS')\n",
        "\n",
        "from f5_tts.api import F5TTS\n",
        "\n",
        "# Initialize F5TTS\n",
        "f5tts = F5TTS()\n",
        "\n",
        "# Generate audio\n",
        "audio = f5tts.infer(\n",
        "    ref_file=\"{output_path}\",\n",
        "    ref_text=\"{reference_text}\",\n",
        "    gen_text=\"{target_text}\",\n",
        "    cross_fade_duration=0.15,\n",
        "    speed=1.0\n",
        ")\n",
        "\n",
        "# Handle tuple/tensor issue properly\n",
        "if isinstance(audio, tuple):\n",
        "    audio = audio[0]\n",
        "\n",
        "print(f\"Audio type: {{type(audio)}}\")\n",
        "if hasattr(audio, 'shape'):\n",
        "    print(f\"Audio shape: {{audio.shape}}\")\n",
        "\n",
        "# Convert numpy array to torch tensor first\n",
        "if isinstance(audio, np.ndarray):\n",
        "    print(\"Converting numpy array to torch tensor...\")\n",
        "    audio = torch.from_numpy(audio.copy())\n",
        "\n",
        "# Now handle tensor shape issues\n",
        "if hasattr(audio, 'shape'):\n",
        "    # Ensure correct tensor format\n",
        "    if len(audio.shape) == 1:\n",
        "        audio = audio.unsqueeze(0)  # Add channel dimension\n",
        "    elif len(audio.shape) == 3:\n",
        "        audio = audio.squeeze(0)   # Remove batch dimension\n",
        "\n",
        "    # Make sure channels are first dimension\n",
        "    if audio.shape[0] > audio.shape[1]:\n",
        "        audio = audio.transpose(0, 1)\n",
        "\n",
        "    print(f\"Final audio shape: {{audio.shape}}\")\n",
        "\n",
        "# Save audio with proper error handling\n",
        "try:\n",
        "    torchaudio.save(\"/content/generated_voice.wav\", audio, 24000)\n",
        "    print(\"‚úÖ Audio saved successfully to /content/generated_voice.wav!\")\n",
        "except Exception as save_error:\n",
        "    print(f\"Save error: {{save_error}}\")\n",
        "    # Try alternative save method\n",
        "    try:\n",
        "        import soundfile as sf\n",
        "        if hasattr(audio, 'numpy'):\n",
        "            audio_np = audio.numpy()\n",
        "        else:\n",
        "            audio_np = audio\n",
        "\n",
        "        if len(audio_np.shape) > 1:\n",
        "            audio_np = audio_np[0]  # Take first channel\n",
        "\n",
        "        sf.write(\"/content/generated_voice.wav\", audio_np, 24000)\n",
        "        print(\"‚úÖ Audio saved using soundfile!\")\n",
        "    except Exception as sf_error:\n",
        "        print(f\"Soundfile save error: {{sf_error}}\")\n",
        "        # Final fallback - save as numpy\n",
        "        if isinstance(audio, torch.Tensor):\n",
        "            audio_np = audio.numpy()\n",
        "        else:\n",
        "            audio_np = audio\n",
        "\n",
        "        np.save(\"/content/generated_voice.npy\", audio_np)\n",
        "        print(\"Audio saved as numpy array to /content/generated_voice.npy\")\n",
        "'''\n",
        "\n",
        "            # Write and execute script\n",
        "            with open('/content/generate_voice.py', 'w') as f:\n",
        "                f.write(script_content)\n",
        "\n",
        "            # Run the script\n",
        "            result = subprocess.run([sys.executable, '/content/generate_voice.py'],\n",
        "                                  capture_output=True, text=True,\n",
        "                                  env={**os.environ, 'PYTHONHASHSEED': '0'})\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"‚úÖ Voice generated using script approach!\")\n",
        "                print(\"Output:\", result.stdout)\n",
        "            else:\n",
        "                print(f\"Script approach error: {result.stderr}\")\n",
        "                print(\"Script output:\", result.stdout)\n",
        "\n",
        "        except Exception as e3:\n",
        "            print(f\"‚ùå All approaches failed. Error: {e3}\")\n",
        "            print(\"Please try running the notebook again or check GPU memory.\")\n",
        "\n",
        "# Additional fallback - try using direct torchaudio operations\n",
        "print(\"\\nTrying direct audio generation fallback...\")\n",
        "try:\n",
        "    # Check if generated file exists and try to load/resave it properly\n",
        "    potential_files = [\"/content/generated_voice.wav\", \"/tmp/generated_audio.wav\"]\n",
        "\n",
        "    for file_path in potential_files:\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"Found audio file: {file_path}\")\n",
        "            try:\n",
        "                # Load and resave with proper format\n",
        "                waveform, sample_rate = torchaudio.load(file_path)\n",
        "                print(f\"Loaded audio shape: {waveform.shape}, sample_rate: {sample_rate}\")\n",
        "\n",
        "                # Ensure proper format\n",
        "                if len(waveform.shape) == 1:\n",
        "                    waveform = waveform.unsqueeze(0)\n",
        "\n",
        "                # Save with corrected format\n",
        "                output_path_fixed = \"/content/generated_voice_fixed.wav\"\n",
        "                torchaudio.save(output_path_fixed, waveform, sample_rate)\n",
        "                print(f\"‚úÖ Audio successfully saved to: {output_path_fixed}\")\n",
        "                break\n",
        "\n",
        "            except Exception as load_error:\n",
        "                print(f\"Error processing {file_path}: {load_error}\")\n",
        "                continue\n",
        "\n",
        "except Exception as fallback_error:\n",
        "    print(f\"Fallback approach failed: {fallback_error}\")\n",
        "\n",
        "print(\"\\nüéµ Voice cloning process completed. Check the output files!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m89NCqIPj3Kt",
        "outputId": "a4e881cf-b0a6-4060-a5c4-11b48fca2a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üé§ Generating cloned voice...\n",
            "Using device: cuda\n",
            "‚ùå Direct inference failed: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
            "Trying gradio interface approach...\n",
            "‚ùå Gradio approach failed: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
            "Trying simple file-based generation...\n",
            "‚úÖ Voice generated using script approach!\n",
            "Output: Download Vocos from huggingface charactr/vocos-mel-24khz\n",
            "\n",
            "vocab :  /content/F5-TTS/src/f5_tts/infer/examples/vocab.txt\n",
            "token :  custom\n",
            "model :  /root/.cache/huggingface/hub/models--SWivid--F5-TTS/snapshots/84e5a410d9cead4de2f847e7c9369a6440bdfaca/F5TTS_v1_Base/model_1250000.safetensors \n",
            "\n",
            "Converting audio...\n",
            "Using custom reference text...\n",
            "\n",
            "ref_text   You just tell me what works, date, time, and your preferred location. We'll arrange everything for you. No pressure. Seriously. I'm just here to help you. \n",
            "gen_text 0 Hey Welcome to Nexi, I'm your personal assistant to help you with all your jaguar land rover queries. We have a wide range of car from SUV to sports,\n",
            "gen_text 1 tell me what should i help you with.\n",
            "\n",
            "\n",
            "Generating audio in 2 batches...\n",
            "Audio type: <class 'numpy.ndarray'>\n",
            "Audio shape: (305392,)\n",
            "Converting numpy array to torch tensor...\n",
            "Final audio shape: torch.Size([1, 305392])\n",
            "‚úÖ Audio saved successfully to /content/generated_voice.wav!\n",
            "\n",
            "\n",
            "Trying direct audio generation fallback...\n",
            "Found audio file: /content/generated_voice.wav\n",
            "Loaded audio shape: torch.Size([1, 305392]), sample_rate: 24000\n",
            "‚úÖ Audio successfully saved to: /content/generated_voice_fixed.wav\n",
            "\n",
            "üéµ Voice cloning process completed. Check the output files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Pickling the model\n",
        "import pickle\n",
        "\n",
        "# Only attempt to pickle the model if it was successfully loaded/defined\n",
        "if 'model' in locals() and model is not None:\n",
        "    try:\n",
        "        with open('model_pickle.pkl', 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "        print(\"‚úÖ Model successfully pickled!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error pickling model: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Model was not successfully loaded or defined in the previous cell. Skipping pickling.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbAN-Yh5q1OS",
        "outputId": "f66e559a-1bc8-4f15-be4d-20b1d57fe44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model successfully pickled!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}